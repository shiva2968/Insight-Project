{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import spacy\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_df = pd.read_csv('New_Data/bbc.csv', encoding='iso-8859-1')\n",
    "news_df = pd.read_csv('New_Data/mixed.csv', encoding='iso-8859-1')\n",
    "news_large_df = pd.read_csv('New_Data/mixed_large.csv', encoding='iso-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_df = bbc_df.drop(columns=['Unnamed: 0']).rename(columns={'row_article': 'text'})\n",
    "news_df = news_df.drop(columns=['author', 'date', 'headlines', 'read_more']).rename(columns=\n",
    "                                                                          {'text': 'summary', 'ctext': 'text'})\n",
    "news_large_df = news_large_df.rename(columns={'headlines': 'summary'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = news_large_df.append(news_df, ignore_index=True, sort=False)\n",
    "data = data.append(bbc_df, ignore_index=True, sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[:5000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   summary  5000 non-null   object\n",
      " 1   text     5000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 78.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleantext(column):\n",
    "    for row in column:\n",
    "        row=re.sub(\"(\\\\t)\", ' ', str(row)).lower() \n",
    "        row=re.sub(\"(\\\\r)\", ' ', str(row)).lower() \n",
    "        row=re.sub(\"(\\\\n)\", ' ', str(row)).lower() \n",
    "        row=re.sub(\"(__+)\", ' ', str(row)).lower()   \n",
    "        row=re.sub(\"(--+)\", ' ', str(row)).lower()   \n",
    "        row=re.sub(\"(~~+)\", ' ', str(row)).lower()   \n",
    "        row=re.sub(\"(\\+\\++)\", ' ', str(row)).lower()   \n",
    "        row=re.sub(\"(\\.\\.+)\", ' ', str(row)).lower()   \n",
    "        row=re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", ' ', str(row)).lower()  \n",
    "        row=re.sub(\"(mailto:)\", ' ', str(row)).lower() \n",
    "        row=re.sub(r\"(\\\\x9\\d)\", ' ', str(row)).lower() \n",
    "        row=re.sub(\"([iI][nN][cC]\\d+)\", 'INC_NUM', str(row)).lower() \n",
    "        row=re.sub(\"([cC][mM]\\d+)|([cC][hH][gG]\\d+)\", 'CM_NUM', str(row)).lower() \n",
    "        row=re.sub(\"(\\.\\s+)\", ' ', str(row)).lower() \n",
    "        row=re.sub(\"(\\-\\s+)\", ' ', str(row)).lower() \n",
    "        row=re.sub(\"(\\:\\s+)\", ' ', str(row)).lower() \n",
    "        row=re.sub(\"(\\s+.\\s+)\", ' ', str(row)).lower() \n",
    "        try:\n",
    "            url = re.search(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)', str(row))\n",
    "            repl_url = url.group(3)\n",
    "            row = re.sub(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)',repl_url, str(row))\n",
    "        except:\n",
    "            pass \n",
    "\n",
    "        row = re.sub(\"(\\s+)\",' ',str(row)).lower()       \n",
    "        row=re.sub(\"(\\s+.\\s+)\", ' ', str(row)).lower() \n",
    "    \n",
    "        yield row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['ner', 'parser']) \n",
    "text = [str(doc) for doc in nlp.pipe(cleantext(data.text), batch_size=5000, n_threads=-1)]\n",
    "summary = ['_START_ '+ str(doc) + ' _END_' for doc in nlp.pipe(cleantext(data.summary), \n",
    "                                                               batch_size=5000, n_threads=-1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_len = 100\n",
    "max_summary_len = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = np.array(data.text)\n",
    "cleaned_summary = np.array(data.summary)\n",
    "\n",
    "short_text = []\n",
    "short_summary = []\n",
    "\n",
    "for i in range(len(cleaned_text)):\n",
    "    if(len(cleaned_summary[i].split()) <= max_summary_len and len(cleaned_text[i].split()) <= max_text_len):\n",
    "        short_text.append(cleaned_text[i])\n",
    "        short_summary.append(cleaned_summary[i])\n",
    "        \n",
    "new_data = pd.DataFrame({'text':short_text, 'summary':short_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sostok Delhi techie wins free food from Swiggy for one year on CRED eostok'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.summary = new_data.summary.apply(lambda x : 'sostok '+ x + ' eostok')\n",
    "new_data.summary[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K \n",
    "import gensim\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_tst, y_tr, y_tst = train_test_split(np.array(new_data.text), np.array(new_data.summary),\n",
    "                                         test_size=0.2, random_state=12, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of X vocab6439\n"
     ]
    }
   ],
   "source": [
    "thresh = 4\n",
    "cnt = 0\n",
    "tot_cnt = 0\n",
    "freq = 0\n",
    "tot_freq = 0\n",
    "for key, value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt = tot_cnt + 1\n",
    "    tot_freq = tot_freq + value\n",
    "    if(value < thresh):\n",
    "        cnt = cnt + 1\n",
    "        freq = freq + value\n",
    "\n",
    "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "x_tr_seq = x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_tst_seq = x_tokenizer.texts_to_sequences(x_tst)\n",
    "x_tr = pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_tst = pad_sequences(x_tst_seq, maxlen=max_text_len, padding='post')\n",
    "x_voc = x_tokenizer.num_words + 1\n",
    "print(\"size of X vocab{}\".format(x_voc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Y vocab1324\n"
     ]
    }
   ],
   "source": [
    "thresh = 6\n",
    "cnt = 0\n",
    "tot_cnt = 0\n",
    "freq = 0\n",
    "tot_freq = 0\n",
    "for key, value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt = tot_cnt+1\n",
    "    tot_freq = tot_freq+value\n",
    "    if(value < thresh):\n",
    "        cnt = cnt + 1\n",
    "        freq =freq + value\n",
    "\n",
    "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "y_tr_seq = y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_tst_seq = y_tokenizer.texts_to_sequences(y_tst) \n",
    "y_tr = pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
    "y_tst = pad_sequences(y_tst_seq, maxlen=max_summary_len, padding='post')\n",
    "y_voc  =   y_tokenizer.num_words +1\n",
    "print(\"Size of Y vocab{}\".format(y_voc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = []\n",
    "for i in range(len(y_tr)):\n",
    "    cnt = 0\n",
    "    for j in y_tr[i]:\n",
    "        if j != 0:\n",
    "            cnt = cnt + 1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_tr = np.delete(y_tr, ind, axis=0)\n",
    "x_tr = np.delete(x_tr, ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind =[]\n",
    "for i in range(len(y_tst)):\n",
    "    cnt=0\n",
    "    for j in y_tst[i]:\n",
    "        if j != 0:\n",
    "            cnt = cnt + 1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_tst = np.delete(y_tst,ind, axis=0)\n",
    "x_tst = np.delete(x_tst,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 100, 200)     1287800     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 100, 300), ( 601200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 100, 300), ( 721200      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 200)    264800      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 100, 300), ( 721200      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 300),  601200      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 1324)   398524      lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,595,924\n",
      "Trainable params: 4,595,924\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "latent_dim = 300\n",
    "embedding_dim = 200\n",
    "\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "enc_emb =  Embedding(x_voc, embedding_dim, trainable=True)(encoder_inputs)\n",
    "\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "encoder_lstm2 = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "encoder_lstm3 = LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm3(encoder_output2)\n",
    "\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3995 samples, validate on 999 samples\n",
      "Epoch 1/50\n",
      "3995/3995 [==============================] - 383s 96ms/sample - loss: 4.0810 - val_loss: 3.4906\n",
      "Epoch 2/50\n",
      "3995/3995 [==============================] - 381s 95ms/sample - loss: 3.4823 - val_loss: 3.1928\n",
      "Epoch 3/50\n",
      "3995/3995 [==============================] - 401s 100ms/sample - loss: 3.3604 - val_loss: 3.1374\n",
      "Epoch 4/50\n",
      "3995/3995 [==============================] - 477s 119ms/sample - loss: 3.3644 - val_loss: 3.1152\n",
      "Epoch 5/50\n",
      "3995/3995 [==============================] - 406s 102ms/sample - loss: 3.2881 - val_loss: 3.1213\n",
      "Epoch 6/50\n",
      "3995/3995 [==============================] - 386s 97ms/sample - loss: 3.2540 - val_loss: 3.0780\n",
      "Epoch 7/50\n",
      "3995/3995 [==============================] - 386s 97ms/sample - loss: 3.2227 - val_loss: 3.0656\n",
      "Epoch 8/50\n",
      "3995/3995 [==============================] - 385s 96ms/sample - loss: 3.1879 - val_loss: 3.0516\n",
      "Epoch 9/50\n",
      "3995/3995 [==============================] - 384s 96ms/sample - loss: 3.1540 - val_loss: 3.0453\n",
      "Epoch 10/50\n",
      "3995/3995 [==============================] - 376s 94ms/sample - loss: 3.1225 - val_loss: 3.0066\n",
      "Epoch 11/50\n",
      "3995/3995 [==============================] - 377s 94ms/sample - loss: 3.0934 - val_loss: 2.9958\n",
      "Epoch 12/50\n",
      "3995/3995 [==============================] - 375s 94ms/sample - loss: 3.0614 - val_loss: 2.9940\n",
      "Epoch 13/50\n",
      "3995/3995 [==============================] - 376s 94ms/sample - loss: 3.0342 - val_loss: 2.9649\n",
      "Epoch 14/50\n",
      "3995/3995 [==============================] - 377s 94ms/sample - loss: 3.0028 - val_loss: 2.9490\n",
      "Epoch 15/50\n",
      "3995/3995 [==============================] - 377s 94ms/sample - loss: 2.9750 - val_loss: 2.9565\n",
      "Epoch 16/50\n",
      "3995/3995 [==============================] - 395s 99ms/sample - loss: 2.9400 - val_loss: 2.9352\n",
      "Epoch 17/50\n",
      "3995/3995 [==============================] - 385s 96ms/sample - loss: 2.9114 - val_loss: 2.9199\n",
      "Epoch 18/50\n",
      "3995/3995 [==============================] - 376s 94ms/sample - loss: 2.8795 - val_loss: 2.9109\n",
      "Epoch 19/50\n",
      "3995/3995 [==============================] - 375s 94ms/sample - loss: 2.8506 - val_loss: 2.9057\n",
      "Epoch 20/50\n",
      "3995/3995 [==============================] - 378s 95ms/sample - loss: 2.8221 - val_loss: 2.9063\n",
      "Epoch 21/50\n",
      "3995/3995 [==============================] - 376s 94ms/sample - loss: 2.7902 - val_loss: 2.8970\n",
      "Epoch 22/50\n",
      "3995/3995 [==============================] - 376s 94ms/sample - loss: 2.7624 - val_loss: 2.8677\n",
      "Epoch 23/50\n",
      "3995/3995 [==============================] - 376s 94ms/sample - loss: 2.7328 - val_loss: 2.8636\n",
      "Epoch 24/50\n",
      "3995/3995 [==============================] - 380s 95ms/sample - loss: 2.7019 - val_loss: 2.8606\n",
      "Epoch 25/50\n",
      "3995/3995 [==============================] - 376s 94ms/sample - loss: 2.6722 - val_loss: 2.8678\n",
      "Epoch 26/50\n",
      "3995/3995 [==============================] - 378s 95ms/sample - loss: 2.6447 - val_loss: 2.8626\n",
      "Epoch 00026: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:,1:],\n",
    "                    epochs=50, callbacks=[es], batch_size=128, \n",
    "                    validation_data=([x_tst, y_tst[:,:-1]],\n",
    "                                       y_tst.reshape(y_tst.shape[0], y_tst.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label = 'train')\n",
    "pyplot.plot(history.history['val_loss'], label = 'test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_word_index = y_tokenizer.index_word\n",
    "reverse_source_word_index = x_tokenizer.index_word\n",
    "target_word_index = y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the feature vector\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs) \n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, \n",
    "                                                                             decoder_state_input_c])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) \n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "      \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        \n",
    "        if(sampled_token!='eostok'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
    "            newString = newString + reverse_target_word_index[i] + ' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString = ''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString = newString + reverse_source_word_index[i] + ' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0,10):\n",
    "#     print(\"Review:\",seq2text(x_tst[i]))\n",
    "#     print(\"Original summary:\",seq2summary(y_tr[i]))\n",
    "#     print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test = \n",
    "\"\"\" \n",
    "We know the problem with these accounts should be resolved now and we apologise for inconvenience.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tokenizer.fit_on_texts(sample_test)\n",
    "x_val_seq = x_tokenizer.texts_to_sequences(sample_test)\n",
    "x_val = pad_sequences(x_val_seq, padding='post')\n",
    "x_val = np.reshape(x_val,(x_val.size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  4,  1,  0, 20,  3,  2,  4,  0, 10, 11,  1,  0, 14, 12,  2, 15,\n",
       "        5,  1, 16,  0,  4,  6, 10, 11,  0, 17, 16,  7,  6,  5,  0,  7,  8,\n",
       "        8,  2, 18,  3, 10,  9,  0,  9, 11,  2, 18,  5, 13,  0, 15,  1,  0,\n",
       "       12,  1,  9,  2,  5, 19,  1, 13,  0,  3,  2,  4,  0,  7,  3, 13,  0,\n",
       "        4,  1,  0,  7, 14,  2,  5,  2, 17,  6,  9,  1,  0, 21,  2, 12,  0,\n",
       "        6,  3,  8,  2,  3, 19,  1,  3,  6,  1,  3,  8,  1,  0,  0])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' man who to get in up'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sequence(x_val.reshape(1,max_text_len))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
